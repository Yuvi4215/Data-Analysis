{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51542e5",
   "metadata": {},
   "source": [
    "\n",
    "# STEP 6: Handle Duplicate Data (Complete Pandas Guide)\n",
    "\n",
    "This notebook covers **ALL practical and real-world ways** to DETECT, ANALYZE,\n",
    "and REMOVE duplicate data in a Pandas DataFrame.\n",
    "\n",
    "Focus: **exact duplicates, key-based duplicates, latest-record logic, and best practices**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544e0ed",
   "metadata": {},
   "source": [
    "## 1. Sample Dataset with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    \"order_id\": [1001, 1002, 1002, 1003, 1004, 1004, 1004],\n",
    "    \"customer\": [\"Alice\", \"Bob\", \"Bob\", \"Charlie\", \"David\", \"David\", \"David\"],\n",
    "    \"amount\": [2500, 1800, 1800, 2200, 3000, 3000, 3000],\n",
    "    \"order_date\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-02\",\n",
    "                   \"2024-01-03\", \"2024-01-04\", \"2024-01-04\", \"2024-01-04\"]\n",
    "})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca3298",
   "metadata": {},
   "source": [
    "## 2. Detect Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8556eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.duplicated()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d812d04",
   "metadata": {},
   "source": [
    "## 3. Count Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e94c96",
   "metadata": {},
   "source": [
    "## 4. View Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df.duplicated()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02beaa7f",
   "metadata": {},
   "source": [
    "## 5. Detect Duplicates Based on Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.duplicated(subset=['order_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf155f",
   "metadata": {},
   "source": [
    "## 6. View Duplicates Based on Business Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df.duplicated(subset=['order_id'], keep=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274936d",
   "metadata": {},
   "source": [
    "## 7. Remove Exact Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_no_exact_dup = df.drop_duplicates()\n",
    "df_no_exact_dup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd738623",
   "metadata": {},
   "source": [
    "## 8. Remove Duplicates Based on Key (Keep First)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76133d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_keep_first = df.drop_duplicates(subset=['order_id'], keep='first')\n",
    "df_keep_first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfb24d",
   "metadata": {},
   "source": [
    "## 9. Remove Duplicates Based on Key (Keep Last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_keep_last = df.drop_duplicates(subset=['order_id'], keep='last')\n",
    "df_keep_last\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375af5b",
   "metadata": {},
   "source": [
    "## 10. Latest Record Wins (Sort + Drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sorted = df.copy()\n",
    "df_sorted['order_date'] = pd.to_datetime(df_sorted['order_date'])\n",
    "df_sorted = df_sorted.sort_values('order_date')\n",
    "df_latest = df_sorted.drop_duplicates(subset=['order_id'], keep='last')\n",
    "df_latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046fa79",
   "metadata": {},
   "source": [
    "## 11. Remove Duplicates Using Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_boolean = df[~df.duplicated(subset=['order_id'])]\n",
    "df_boolean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86e12a",
   "metadata": {},
   "source": [
    "## 12. Inplace Duplicate Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eaad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_inplace = df.copy()\n",
    "df_inplace.drop_duplicates(subset=['order_id'], inplace=True)\n",
    "df_inplace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87c18d",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Best Practices & Interview Notes\n",
    "- Always detect before removing duplicates\n",
    "- Prefer business keys (`order_id`, `user_id`) over full-row match\n",
    "- Use `keep='last'` for latest-record logic\n",
    "- Sorting before removal is critical\n",
    "- Never remove duplicates blindly in audit data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654493e",
   "metadata": {},
   "source": [
    "\n",
    "## ✔ Summary\n",
    "- `duplicated()` detects duplicates\n",
    "- `drop_duplicates()` removes them\n",
    "- `subset` and `keep` control logic\n",
    "- Business rules define what a duplicate means\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
