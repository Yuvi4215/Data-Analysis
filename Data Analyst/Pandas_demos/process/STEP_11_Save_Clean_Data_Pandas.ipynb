{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b0d6fb",
   "metadata": {},
   "source": [
    "\n",
    "# STEP 11: Save Clean Data (Complete Pandas Guide)\n",
    "\n",
    "This notebook covers **ALL practical and real-world ways** to SAVE cleaned data\n",
    "after validation.\n",
    "\n",
    "Focus: **CSV, Excel, JSON, Parquet, databases, versioning, and best practices**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d14b5d",
   "metadata": {},
   "source": [
    "## 1. Sample Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    \"order_id\": [1001, 1002, 1003, 1004],\n",
    "    \"customer\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"amount\": [2500.0, 1800.0, 2200.0, 3000.0],\n",
    "    \"city\": [\"Mumbai\", \"Delhi\", \"Mumbai\", \"Pune\"],\n",
    "    \"order_date\": pd.to_datetime([\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", \"2024-01-04\"])\n",
    "})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4214fe",
   "metadata": {},
   "source": [
    "## 2. Save Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic CSV\n",
    "df.to_csv(\"clean_data.csv\", index=False)\n",
    "\n",
    "# With custom separator\n",
    "df.to_csv(\"clean_data_pipe.csv\", sep='|', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e6043",
   "metadata": {},
   "source": [
    "## 3. Save Data as Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a67ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Single sheet\n",
    "df.to_excel(\"clean_data.xlsx\", index=False)\n",
    "\n",
    "# Multiple sheets\n",
    "with pd.ExcelWriter(\"clean_data_multi.xlsx\") as writer:\n",
    "    df.to_excel(writer, sheet_name=\"orders\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a6c77",
   "metadata": {},
   "source": [
    "## 4. Save Data as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_json(\"clean_data.json\", orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da15a0",
   "metadata": {},
   "source": [
    "## 5. Save Data as Parquet (Big Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd70459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Requires pyarrow or fastparquet\n",
    "# df.to_parquet(\"clean_data.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd275d",
   "metadata": {},
   "source": [
    "## 6. Save Data as Pickle (Fast, Python-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_pickle(\"clean_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c881c",
   "metadata": {},
   "source": [
    "## 7. Save Data to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine(\"sqlite:///clean_data.db\")\n",
    "# df.to_sql(\"orders\", engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18414ff4",
   "metadata": {},
   "source": [
    "## 8. Versioning Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example naming strategy\n",
    "version = \"v1_0\"\n",
    "file_name = f\"clean_data_{version}.csv\"\n",
    "df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf89c5d",
   "metadata": {},
   "source": [
    "## 9. Compression while Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"clean_data.csv.gz\", compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71761d22",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Best Practices & Interview Notes\n",
    "- Always save AFTER final validation\n",
    "- Prefer CSV or Parquet for analytics\n",
    "- Use versioning for reproducibility\n",
    "- Never overwrite raw data\n",
    "- Compression helps with large datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc29a9",
   "metadata": {},
   "source": [
    "\n",
    "## ✔ Summary\n",
    "- `to_*()` methods export data\n",
    "- Choose format based on use-case\n",
    "- Versioning & compression are enterprise practices\n",
    "- Saving is the final gate of data cleaning\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
